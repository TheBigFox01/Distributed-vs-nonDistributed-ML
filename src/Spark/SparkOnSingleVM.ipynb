{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d41101-4c79-4a84-8ada-1cde5adb68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52e5c32-0192-484a-80e4-85be1a6e9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/22 15:40:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Crea una sessione Spark\n",
    "spark = SparkSession.builder.appName(\"StudentDepressionRandomForest\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e7a0ac-54e1-4540-9571-442b8e2894fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 15:40:51 WARN FileSystem: \"instance-20250422-084356:9000\" is a deprecated filesystem name. Use \"hdfs://instance-20250422-084356:9000/\" instead.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Carica il dataset da HDFS (assumendo che sia stato caricato correttamente)\n",
    "df = spark.read.csv(\"hdfs://instance-20250422-084356:9000/user/hadoop/EDA_Student_Depression_Dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004e7982-4782-420a-a28c-9b8e1b47460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Gender=1, Age=33.0, Academic_Pressure=5.0, CGPA=8.97, Study_Satisfaction=2.0, Sleep_Duration=0, Have_you_ever_had_suicidal_thoughts?=1, Work/Study_Hours=3.0, Financial_Stress=1.0, Family_History_of_Mental_Illness=0, Depression=1, Is_Metropolis=0, Dietary_Habits_Healthy=1, Dietary_Habits_Moderate=0, Dietary_Habits_Unhealthy=0, Degree_bachelor=1, Degree_high_school=0, Degree_masters_phd=0)\n"
     ]
    }
   ],
   "source": [
    "# Visualizza i dati per confermare il caricamento\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc25ba7d-db85-4c59-8638-faa239465b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Creazione della feature \"features\" combinando tutte le colonne numeriche\n",
    "columns = df.columns\n",
    "columns.remove('Depression')  # Rimuoviamo la colonna target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00551a4-887b-419a-927d-d4a69b274a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del VectorAssembler per combinare tutte le features in un'unica colonna\n",
    "assembler = VectorAssembler(inputCols=columns, outputCol=\"features\")\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7d2840-762c-422e-8a11-a139684f771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il modello di Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"Depression\", featuresCol=\"features_scaled\", numTrees=10, maxDepth=5)\n",
    "\n",
    "# Costruisci il pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "# Splitta i dati in training e test (80% training, 20% test)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1deeb4f-4acf-49b4-a301-163fa953c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 15:41:31 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Inizio della misurazione del tempo di addestramento\n",
    "start_time = time.time()\n",
    "\n",
    "# Addestra il modello\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "\n",
    "# Fine della misurazione del tempo di addestramento\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec12925b-1c8c-475e-9596-be3f711ea577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di addestramento: 8.74 secondi\n"
     ]
    }
   ],
   "source": [
    "# Calcola e stampa il tempo di addestramento\n",
    "training_time = end_time - start_time\n",
    "print(f\"Tempo di addestramento: {training_time:.2f} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23dfbdb8-7aa2-4562-8399-b98febcde72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|prediction|Depression|\n",
      "+----------+----------+\n",
      "|       1.0|         0|\n",
      "|       0.0|         0|\n",
      "|       0.0|         0|\n",
      "|       0.0|         0|\n",
      "|       1.0|         0|\n",
      "|       0.0|         0|\n",
      "|       1.0|         1|\n",
      "|       0.0|         0|\n",
      "|       0.0|         0|\n",
      "|       0.0|         0|\n",
      "+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fai le predizioni sul set di test\n",
    "predictions = pipeline_model.transform(test_data)\n",
    "\n",
    "# Visualizza le prime 10 predizioni\n",
    "predictions.select(\"prediction\", \"Depression\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577045cb-0e2f-4511-ae05-f6b18a4faf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9039813955598632\n",
      "\n",
      "Accuracy score on the test set: 0.8406504065040651\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      2264\n",
      "           1       0.85      0.89      0.87      3271\n",
      "\n",
      "    accuracy                           0.84      5535\n",
      "   macro avg       0.84      0.83      0.83      5535\n",
      "weighted avg       0.84      0.84      0.84      5535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valutazione del modello utilizzando l'AUC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Depression\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# Calcolare altre metriche come l'accuratezza\n",
    "t_test = predictions.select('Depression').toPandas()\n",
    "t_hat = predictions.select('prediction').toPandas()\n",
    "print(f\"\\nAccuracy score on the test set: {accuracy_score(t_test, t_hat)}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(t_test, t_hat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
